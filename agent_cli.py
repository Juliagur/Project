#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ LangChain:
"""

import os

os.environ["HF_HOME"] = r"D:\Ğ®Ğ»Ñ_ÑƒĞ½Ğ¸Ğº\5 ĞºÑƒÑ€Ñ\pr\itogProject\hf_cache"
os.environ["HF_HUB_CACHE"] = r"D:\Ğ®Ğ»Ñ_ÑƒĞ½Ğ¸Ğº\5 ĞºÑƒÑ€Ñ\pr\itogProject\hf_cache"
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
os.environ["TRANSFORMERS_VERBOSITY"] = "error"

import warnings

warnings.filterwarnings("ignore", category=UserWarning, module="transformers")

from typing import Dict, Any, List
import json
import re
from datetime import datetime

# === 1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ===
print("ğŸ” Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Phi-3-mini...")
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch

MODEL_NAME = "microsoft/Phi-3-mini-4k-instruct"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float32,
    attn_implementation="eager",
    use_cache=True
)
model.to("cpu")

hf_pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=256,
    do_sample=False,
    temperature=0.1,
    pad_token_id=tokenizer.eos_token_id,
    return_full_text=False,
    truncation=True
)

from langchain_huggingface import HuggingFacePipeline

llm = HuggingFacePipeline(pipeline=hf_pipe)
print("âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°!\n")


# === 2. MEMORY: Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ° ===
class SimpleMemory:
    def __init__(self):
        self.chat_history: List[str] = []

    def add(self, user: str, ai: str):
        self.chat_history.append(f"ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: {user}")
        self.chat_history.append(f"ĞĞ³ĞµĞ½Ñ‚: {ai}")

    def get_context(self, last_n: int = 4) -> str:
        return "\n".join(self.chat_history[-last_n:]) if self.chat_history else "ĞĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸."


memory = SimpleMemory()

# === 3. TOOLS  ===
from langchain_core.tools import tool


@tool
def check_weather(location: str) -> str:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñƒ Ğ² ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğµ."""
    return f"ğŸŒ¤ï¸ Ğ’ {location} ÑĞµĞ¹Ñ‡Ğ°Ñ +22Â°C, ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ğ¾."


@tool
def book_appointment(date: str, time: str, service: str) -> str:
    """Ğ‘Ñ€Ğ¾Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ğ½Ğ° ÑƒÑĞ»ÑƒĞ³Ñƒ."""
    return f"âœ… Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ğ½Ğ° '{service}' Ğ·Ğ°Ğ±Ñ€Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ½Ğ° {date} Ğ² {time}."


@tool
def search_restaurant(cuisine: str, city: str) -> str:
    """Ğ˜Ñ‰ĞµÑ‚ Ñ€ĞµÑÑ‚Ğ¾Ñ€Ğ°Ğ½Ñ‹ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ ĞºÑƒÑ…Ğ½Ğ¸."""
    return f"ğŸ ĞĞ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ñ€ĞµÑÑ‚Ğ¾Ñ€Ğ°Ğ½Ñ‹ {cuisine} ĞºÑƒÑ…Ğ½Ğ¸ Ğ² {city}: 'La Bella', 'Taste of Home'."


# TOOL
@tool
def get_current_time(dummy: str = "") -> str:
    """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ´Ğ°Ñ‚Ñƒ Ğ¸ Ğ²Ñ€ĞµĞ¼Ñ."""
    now = datetime.now().strftime("%d.%m.%Y %H:%M")
    return f"ğŸ•’ Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ: {now}"


# === 4. RETRIEVAL (Ğ±Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹) ===
KNOWLEDGE_BASE = {
    "Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ´ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸": "ĞœÑ‹ Ğ½Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ¼ Ğ²Ğ°ÑˆĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ. Ğ’ÑĞµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾.",
    "Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚": "Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚ Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶ĞµĞ½, Ñ‚Ğ°Ğº ĞºĞ°Ğº ÑƒÑĞ»ÑƒĞ³Ğ° Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ.",
    "Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ°": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ğ½Ğ° support@example.com"
}


def retrieve_info(query: str) -> str:
    """Ğ­Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Retrieval Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹."""
    query = query.lower()
    for key, value in KNOWLEDGE_BASE.items():
        if key in query:
            return value
    return None


# === 5. TOOLS + RETRIEVAL ===
tools = [check_weather, book_appointment, search_restaurant, get_current_time]
tool_dict = {tool.name: tool for tool in tools}

# === 6. PROMPT Ñ MEMORY Ğ¸ TOOLS ===
from langchain_core.prompts import PromptTemplate

PROMPT_TEMPLATE = """
Ğ¢Ñ‹ â€” ÑƒĞ¼Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚. Ğ£ Ñ‚ĞµĞ±Ñ ĞµÑÑ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑĞ¼:
{tool_descriptions}

Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°:
{chat_history}

ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
1. Ğ•ÑĞ»Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ĞµĞ¹ â€” Ğ²Ñ‹Ğ²ĞµĞ´Ğ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ JSON:
{{"function": "Ğ¸Ğ¼Ñ", "args": {{"Ğ¿Ğ°Ñ€Ğ°Ğ¼": "Ğ·Ğ½Ğ°Ñ‡"}}}}
2. Ğ•ÑĞ»Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ ĞºĞ°ÑĞ°ĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ°, Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ â€” Ğ¾Ñ‚Ğ²ĞµÑ‚ÑŒ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ.
3. Ğ˜Ğ½Ğ°Ñ‡Ğµ â€” Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ÑĞ°Ğ¼Ğ¾ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ¾.

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:
Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ: Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸?
ĞÑ‚Ğ²ĞµÑ‚: {{"function": "get_current_time", "args": {{}}}}

Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ: {input}
ĞÑ‚Ğ²ĞµÑ‚:
""".strip()

tool_descriptions = "\n".join([f"- {t.name}: {t.description}" for t in tools])

# === 7. CHAIN (Ñ Ğ½Ğ°ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼) ===
from langchain_core.chains import Chain


class FunctionCallingChain(Chain):
    """Ğ¦ĞµĞ¿Ğ¾Ñ‡ĞºĞ° Ñ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹ Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒÑ."""
    llm: Any
    prompt_template: str
    tool_dict: Dict[str, Any]
    memory: Any

    @property
    def input_keys(self) -> List[str]:
        return ["input"]

    @property
    def output_keys(self) -> List[str]:
        return ["output"]

    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        user_input = inputs["input"]

        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        chat_history = self.memory.get_context()

        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚
        full_prompt = self.prompt_template.format(
            tool_descriptions=tool_descriptions,
            chat_history=chat_history,
            input=user_input
        )

        # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ
        raw_output = self.llm.invoke(full_prompt)
        result = self._parse_json(raw_output)

        # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ°
        if result.get("function") == "none":
            response = result.get("response", "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ñ Ğ½Ğµ Ğ¿Ğ¾Ğ½ÑĞ».")
        else:
            func_name = result.get("function")
            args = result.get("args", {})
            if func_name in self.tool_dict:
                response = self.tool_dict[func_name].func(**args)
            else:
                response = "ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ."

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Retrieval
        if "function" not in result or result["function"] == "none":
            retrieved = retrieve_info(user_input)
            if retrieved:
                response = retrieved

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ
        self.memory.add(user_input, response)
        return {"output": response}

    def _parse_json(self, text: str) -> Dict[str, Any]:
        try:
            match = re.search(r"\{.*\}", text, re.DOTALL)
            if match:
                return json.loads(match.group().replace('\n', ' '))
        except Exception:
            pass
        return {"function": "none", "response": "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ½ÑÑ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ."}


# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºÑƒ
chain = FunctionCallingChain(
    llm=llm,
    prompt_template=PROMPT_TEMPLATE,
    tool_dict=tool_dict,
    memory=memory
)


# === 8. Ğ—ĞĞŸĞ£Ğ¡Ğš ===
def run_tests():
    print("ğŸ§ª Ğ¢ĞµÑÑ‚Ñ‹ Ñ Memory Ğ¸ Custom Tool...\n")
    tests = [
        "Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸?",
        "ĞšĞ°ĞºĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° Ğ² Ğ¡Ğ°Ñ€Ğ°Ñ‚Ğ¾Ğ²Ğµ?",
        "ĞšĞ°ĞºĞ°Ñ Ñƒ Ğ²Ğ°Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ´ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸?",
        "Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸?"  # Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Memory
    ]
    for q in tests:
        result = chain({"input": q})
        print(f"Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {q}")
        print(f"ĞÑ‚Ğ²ĞµÑ‚: {result['output']}\n")


def main():
    print("ğŸ¤– Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ñ Memory, Tools Ğ¸ Chain Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½!")
    print("ğŸ’¬ Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ (Ğ¸Ğ»Ğ¸ 'Ğ²Ñ‹Ñ…Ğ¾Ğ´'):\n")
    while True:
        try:
            user_input = input("Ğ’Ñ‹: ").strip()
            if not user_input or user_input.lower() in ("Ğ²Ñ‹Ñ…Ğ¾Ğ´", "exit"):
                break
            result = chain({"input": user_input})
            print(f"ĞĞ³ĞµĞ½Ñ‚: {result['output']}\n")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Ğ’Ñ‹Ñ…Ğ¾Ğ´.")
            break


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        run_tests()
    else:
        main()